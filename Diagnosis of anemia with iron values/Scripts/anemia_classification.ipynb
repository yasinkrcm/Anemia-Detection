{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Anemia Classification using Random Forest\n","\n","## 1. Install Required Libraries\n","\n","Before running the notebook, make sure to install all required libraries.\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pandas in c:\\users\\yasin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.1.4)\n","Requirement already satisfied: scikit-learn in c:\\users\\yasin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.5.0)\n","Requirement already satisfied: numpy in c:\\users\\yasin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yasin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in c:\\users\\yasin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.1 in c:\\users\\yasin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2023.4)\n","Requirement already satisfied: scipy>=1.6.0 in c:\\users\\yasin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.12.0)\n","Requirement already satisfied: joblib>=1.2.0 in c:\\users\\yasin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\yasin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: six>=1.5 in c:\\users\\yasin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install pandas scikit-learn numpy"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.svm import SVC\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.model_selection import GridSearchCV , StratifiedKFold,cross_val_score\n","from sklearn.model_selection import RandomizedSearchCV \n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Load the unprocessed data\n","data = pd.read_csv('../Datas/anemia.csv')\n","\n","# Separate features (X) and target variable (y)\n","X = data.drop('Result', axis=1)\n","y = data['Result']\n","\n","# Apply Min-Max Scaling to all columns except 'Gender'\n","min_max_scaler = MinMaxScaler()\n","X_scaled = X.copy()  # Create a copy of X to apply scaling\n","\n","# Apply Min-Max Scaling to each column except 'Gender'\n","for col in X.columns:\n","    if col != \"Gender\":\n","        X_scaled[col] = min_max_scaler.fit_transform(X[[col]])\n","\n","# Add 'Gender' column back to the scaled data\n","processed_data = X_scaled\n","processed_data['Gender'] = X['Gender'].values\n","\n","# Add the target variable back to the processed dataset\n","processed_data['Result'] = y\n","\n","# Save the processed data to a new CSV file\n","processed_data.to_csv('..//Datas/processed_data.csv', index=False)\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["\n","# Load the processed dataset\n","data = pd.read_csv('..//Datas/processed_data.csv')\n","\n","# Separate features (X) and target variable (y)\n","X = data.drop('Result', axis=1)\n","y = data['Result']\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: Logistic Regression\n","Accuracy: 0.98\n","Confusion Matrix:\n","[[237   8]\n"," [  0 182]]\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.97      0.98       245\n","           1       0.96      1.00      0.98       182\n","\n","    accuracy                           0.98       427\n","   macro avg       0.98      0.98      0.98       427\n","weighted avg       0.98      0.98      0.98       427\n","\n","\n","--------------------------------------------------\n","\n","Model: Decision Tree\n","Accuracy: 1.00\n","Confusion Matrix:\n","[[245   0]\n"," [  0 182]]\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00       245\n","           1       1.00      1.00      1.00       182\n","\n","    accuracy                           1.00       427\n","   macro avg       1.00      1.00      1.00       427\n","weighted avg       1.00      1.00      1.00       427\n","\n","\n","--------------------------------------------------\n","\n","Model: Random Forest\n","Accuracy: 1.00\n","Confusion Matrix:\n","[[245   0]\n"," [  0 182]]\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00       245\n","           1       1.00      1.00      1.00       182\n","\n","    accuracy                           1.00       427\n","   macro avg       1.00      1.00      1.00       427\n","weighted avg       1.00      1.00      1.00       427\n","\n","\n","--------------------------------------------------\n","\n","Model: Support Vector Machine\n","Accuracy: 0.98\n","Confusion Matrix:\n","[[237   8]\n"," [  0 182]]\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.97      0.98       245\n","           1       0.96      1.00      0.98       182\n","\n","    accuracy                           0.98       427\n","   macro avg       0.98      0.98      0.98       427\n","weighted avg       0.98      0.98      0.98       427\n","\n","\n","--------------------------------------------------\n","\n","Model: K-Nearest Neighbors\n","Accuracy: 0.94\n","Confusion Matrix:\n","[[229  16]\n"," [ 10 172]]\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.96      0.93      0.95       245\n","           1       0.91      0.95      0.93       182\n","\n","    accuracy                           0.94       427\n","   macro avg       0.94      0.94      0.94       427\n","weighted avg       0.94      0.94      0.94       427\n","\n","\n","--------------------------------------------------\n","\n","Model: Gradient Boosting\n","Accuracy: 1.00\n","Confusion Matrix:\n","[[245   0]\n"," [  0 182]]\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00       245\n","           1       1.00      1.00      1.00       182\n","\n","    accuracy                           1.00       427\n","   macro avg       1.00      1.00      1.00       427\n","weighted avg       1.00      1.00      1.00       427\n","\n","\n","--------------------------------------------------\n","\n"]}],"source":["\n","\n","# Initialize models\n","models = {\n","    'Logistic Regression': LogisticRegression(max_iter=1000),\n","    'Decision Tree': DecisionTreeClassifier(),\n","    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n","    'Support Vector Machine': SVC(),\n","    'K-Nearest Neighbors': KNeighborsClassifier(),\n","    'Gradient Boosting': GradientBoostingClassifier()\n","}\n","\n","# Train, predict and evaluate each model\n","for name, model in models.items():\n","    # Train the model\n","    model.fit(X_train, y_train)\n","    \n","    # Make predictions\n","    y_pred = model.predict(X_test)\n","    \n","    # Evaluate the model\n","    accuracy = accuracy_score(y_test, y_pred)\n","    conf_matrix = confusion_matrix(y_test, y_pred)\n","    class_report = classification_report(y_test, y_pred)\n","    \n","    print(f\"Model: {name}\")\n","    print(f\"Accuracy: {accuracy:.2f}\")\n","    print(\"Confusion Matrix:\")\n","    print(conf_matrix)\n","    print(\"Classification Report:\")\n","    print(class_report)\n","    print(\"\\n\" + \"-\"*50 + \"\\n\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## Optimal Machine Learning Algorithm"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Accuracy: 1.0\n","Test Accuracy: 1.0\n","\n","Training Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00       556\n","           1       1.00      1.00      1.00       438\n","\n","    accuracy                           1.00       994\n","   macro avg       1.00      1.00      1.00       994\n","weighted avg       1.00      1.00      1.00       994\n","\n","\n","Test Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00       245\n","           1       1.00      1.00      1.00       182\n","\n","    accuracy                           1.00       427\n","   macro avg       1.00      1.00      1.00       427\n","weighted avg       1.00      1.00      1.00       427\n","\n","\n","Confusion Matrix (Test Data):\n","[[245   0]\n"," [  0 182]]\n"]}],"source":["# Load the processed dataset\n","data = pd.read_csv('..//Datas/processed_combined_data.csv')\n","X = data.drop(columns=['Result'])\n","y = data['Result']\n","\n","\n","# Split the data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Define the model\n","model = RandomForestClassifier(n_estimators=100 , random_state=42)\n","\n","# Fit the model\n","model.fit(X_train, y_train)\n","\n","# Make predictions\n","y_train_pred = model.predict(X_train)\n","y_test_pred = model.predict(X_test)\n","\n","# Evaluate the model\n","print(\"Training Accuracy:\", accuracy_score(y_train, y_train_pred))\n","print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n","\n","print(\"\\nTraining Classification Report:\")\n","print(classification_report(y_train, y_train_pred))\n","\n","print(\"\\nTest Classification Report:\")\n","print(classification_report(y_test, y_test_pred))\n","\n","print(\"\\nConfusion Matrix (Test Data):\")\n","print(confusion_matrix(y_test, y_test_pred))"]},{"cell_type":"markdown","metadata":{},"source":["# Why Random Forest\n"]},{"cell_type":"markdown","metadata":{},"source":["## Selection Criteria\n","# Generalization Ability:\n"," Random Forest and Gradient Boosting generally have better generalization ability because they are more complex and use a combination of more models.\n","# Computational Resources: \n","If your computational resources are limited, Decision Tree may be more suitable because it is simpler and faster.\n","# Model Complexity: \n","More complex models (Random Forest and Gradient Boosting) generally perform better but may require more computation and modeling time.\n","## Recommendation.\n","If your data is small or medium-sized and your computational resources are not limited, I recommend you to opt for Random Forest or Gradient Boosting models. These models usually provide better overall performance.\n","\n","If model interpretability is important and your computational resources are limited, Decision Tree may be a good option. However, usually decision trees are suitable for simpler scenarios and for more complex data sets, ensemble methods such as Random Forest or Gradient Boosting perform better.\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":2}
